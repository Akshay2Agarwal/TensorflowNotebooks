{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional neural network\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, \"rb\") as file_handle:\n",
    "        dict = pickle.load(file_handle, encoding='latin1')\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:  ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072) (50000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def clean(data):\n",
    "    imgs = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    grayscale_imgs = imgs.mean(1)\n",
    "    cropped_imgs = grayscale_imgs[:, 4:28, 4:28]\n",
    "    img_data = cropped_imgs.reshape(data.shape[0], -1)\n",
    "    img_size = np.shape(img_data)[1]\n",
    "    means = np.mean(img_data, axis=1)\n",
    "    meansT = means.reshape(len(means), 1)\n",
    "    stds = np.std(img_data, axis=1)\n",
    "    stdsT = stds.reshape(len(stds), 1)\n",
    "    adj_stds = np.maximum(stdsT, 1.0 / np.sqrt(img_size))\n",
    "    normalized = (img_data - meansT) / adj_stds\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def read():\n",
    "    names = unpickle('./data/cifar-10-batches-py/batches.meta')['label_names']\n",
    "    print(\"names: \", names)\n",
    "    data, labels = [], []\n",
    "    for i in range(1, 6):\n",
    "        filename = './data/cifar-10-batches-py/data_batch_'+str(i)\n",
    "        batch_data = unpickle(filename)\n",
    "        if len(data) > 0:\n",
    "            batch_data = unpickle(filename)\n",
    "            data = np.vstack((data, batch_data['data']))\n",
    "            labels = np.hstack((labels, batch_data['labels']))\n",
    "        else:\n",
    "            data = batch_data['data']\n",
    "            labels = batch_data['labels']\n",
    "    \n",
    "    print(np.shape(data), np.shape(labels))\n",
    "    data = clean(data)\n",
    "    data.astype(np.float32)\n",
    "    return names, data, labels\n",
    "\n",
    "names, data, labels = read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def display_some_examples(names, data, labels):\n",
    "    plt.figure()\n",
    "    rows, cols = 4, 4\n",
    "    random_ixs = random.sample(range(len(data)), rows*cols)\n",
    "    for i in range(rows*cols):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        j = random_ixs[i]\n",
    "        plt.title(names[labels[j]])\n",
    "        img = np.reshape(data[j, :], (24, 24))\n",
    "        plt.imshow(img, cmap='Greys_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "display_some_examples(names, data, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_normal((5, 5, 1, 32), dtype=tf.float64))\n",
    "\n",
    "\n",
    "def show_weights(W):\n",
    "    plt.figure()\n",
    "    rows, cols = 4, 8\n",
    "    for i in range(rows*cols):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        img = W[:, :, 0, i]\n",
    "        plt.imshow(img, cmap='Greys_r', interpolation=None)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    w_val = sess.run(W)\n",
    "    show_weights(w_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 24, 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 24, 32)\n(1, 24, 24, 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 24, 32)\n(1, 12, 12, 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12, 12, 32)\n"
     ]
    }
   ],
   "source": [
    "def show_conv_results(data):\n",
    "    plt.figure()\n",
    "    rows, cols = 4, 8\n",
    "    print(data.shape)\n",
    "    for i in range(np.shape(data)[3]):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        img = data[0, :, :, i]\n",
    "        plt.imshow(img, cmap='Greys_r', interpolation='none')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 24, 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 24, 32)\n(1, 24, 24, 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 24, 32)\n(1, 12, 12, 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12, 12, 32)\n"
     ]
    }
   ],
   "source": [
    "raw_data = data[4, :]\n",
    "raw_image = np.reshape(raw_data, (24, 24))\n",
    "plt.figure()\n",
    "plt.imshow(raw_image, cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "x = tf.reshape(raw_data, [-1, 24, 24, 1])\n",
    "\n",
    "b = tf.Variable(tf.random_normal([32], dtype=tf.float64))\n",
    "\n",
    "conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv_with_bias = tf.nn.bias_add(conv, b)\n",
    "conv_out = tf.nn.relu(conv_with_bias)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    conv_val = sess.run(conv)\n",
    "    show_conv_results(conv_val)\n",
    "    print(np.shape(conv_val))\n",
    "    \n",
    "    conv_out_val = sess.run(conv_out)\n",
    "    show_conv_results(conv_out_val)\n",
    "    print(np.shape(conv_out_val))\n",
    "    \n",
    "k = 2\n",
    "maxpool = tf.nn.max_pool(conv_out, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    maxpool_val = sess.run(maxpool)\n",
    "    show_conv_results(maxpool_val)\n",
    "    print(np.shape(maxpool_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1899999976158142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20000000298023224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24500000476837158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2150000035762787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23000000417232513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.19499999284744263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20499999821186066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29499998688697815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2800000011920929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26499998569488525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23499999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.22499999403953552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2549999952316284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23499999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2750000059604645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1850000023841858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.19499999284744263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23999999463558197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20999999344348907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20000000298023224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2549999952316284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1850000023841858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23499999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27000001072883606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25999999046325684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1850000023841858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23999999463558197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed\nEpoch: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27000001072883606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2549999952316284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25999999046325684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20000000298023224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24500000476837158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25999999046325684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2800000011920929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27000001072883606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25999999046325684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2750000059604645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3050000071525574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.22499999403953552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2800000011920929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23000000417232513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2849999964237213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2800000011920929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23499999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2800000011920929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25999999046325684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30000001192092896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2849999964237213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30000001192092896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28999999165534973\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "names, data, labels = read()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 24*24))\n",
    "y = tf.placeholder(tf.float32, shape=(None, len(names)))\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal([5, 5, 1, 64]))\n",
    "b1 = tf.Variable(tf.random.normal([64]))\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([5, 5, 64, 64]))\n",
    "b2 = tf.Variable(tf.random.normal([64]))\n",
    "\n",
    "W3 = tf.Variable(tf.random.normal([6*6*64, 1024]))\n",
    "b3 = tf.Variable(tf.random.normal([1024]))\n",
    "\n",
    "w_out = tf.Variable(tf.random.normal([1024, len(names)]))\n",
    "b_out = tf.Variable(tf.random.normal([len(names)]))\n",
    "\n",
    "\n",
    "def conv_layer(x, W, b):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv_bias =tf.nn.bias_add(conv, b)\n",
    "    conv_out = tf.nn.relu(conv_bias)\n",
    "    return conv_out\n",
    "\n",
    "\n",
    "def maxpool_layer(conv, k=2):\n",
    "    maxpool_layer = tf.nn.max_pool(conv, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "    return maxpool_layer\n",
    "\n",
    "\n",
    "def model():\n",
    "    x_reshaped = tf.reshape(x, [-1, 24, 24, 1])\n",
    "    \n",
    "    conv_out_1 = conv_layer(x_reshaped, W1, b1)\n",
    "    maxpool_out_1 = maxpool_layer(conv_out_1)\n",
    "    \n",
    "    norm_1 = tf.nn.lrn(maxpool_out_1, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)\n",
    "    \n",
    "    conv_out_2 = conv_layer(norm_1, W2, b2)\n",
    "    norm_2 = tf.nn.lrn(conv_out_2, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)\n",
    "    maxpool_out_2 = maxpool_layer(norm_2)\n",
    "    \n",
    "    maxpool_reshaped = tf.reshape(maxpool_out_2, [ -1 , W3.get_shape().as_list()[0]])\n",
    "    local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)\n",
    "    local_out = tf.nn.relu(local)\n",
    "    out = tf.add(tf.matmul(local_out, w_out), b_out)\n",
    "    return out\n",
    "\n",
    "model_op = model()\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model_op, labels=y))\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "correct_predicitons = tf.equal(tf.argmax(model_op, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predicitons, dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    onehot_labels = tf.one_hot(labels, len(names), on_value=1., off_value=0., axis=-1)\n",
    "    onehot_vals = sess.run(onehot_labels)\n",
    "    batch_size = 200\n",
    "    for j in range(1000):\n",
    "        print(\"Epoch:\", j)\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch_data = data[i: i+batch_size, :]\n",
    "            batch_onehot_vals = onehot_vals[i: i+batch_size, :]\n",
    "            _ , accuracy_val = sess.run([train_op, accuracy], feed_dict={x: batch_data, y: batch_onehot_vals})\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Accuracy: {acc}\".format(acc=accuracy_val))\n",
    "        print(\"Epoch {e} completed\".format(e=j))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
